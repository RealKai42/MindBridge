**This document was translated from the Chinese version using AI, and the Chinese version shall prevail.**

<h1 align="center">
  Mind Bridge
</h1>
<p align="center">
  <strong>Exploring AI's empathy and associative reasoning.</strong>
</p>

<p align="center">
  <a href="./README.md">Chinese</a>  
</p>

## Preface
This is not a practical or application-oriented project but an exploratory one. Through this project, we aim to explore AI's capabilities in emotional and associative reasoning.

This is also not a rigorous scientific research project—it's merely an attempt to validate our own thoughts and ideas.

The core of the project lies in the experiments and the interpretation of the results. The code is of low value, and one-third of it is generated by AI.

## Project Background
We believe many of you are somewhat familiar with Shannon's Information Theory. From a broad perspective, the information we transmit is constrained by its carrier; information cannot be generated out of thin air but is limited by its medium.

This description obviously pertains to traditional computer communication. Let's consider communication between two intelligent agents (humans). Here, we assume that the communication is purely textual, without involving facial expressions, tone, body language, etc.

If I say to a friend, "USA, full name," he will fluently respond, "United States of America." This is clearly additional information not carried by the medium itself. The reason this communication is effective is because my friend and I share a common knowledge base, accumulated from our experiences in life—what we can call the fundamental human knowledge and understanding, or **common sense**.

In the pre-AI era, we could easily achieve the conversion from "USA, full name" to "United States of America," for example, by storing the same key-value pairs in two computers to map "USA" to "United States of America." However, this method is not based on fundamental human knowledge and understanding but attempts to solve the problem through exhaustive enumeration.

In the era of large models, we do not consider that their underlying intelligence is emergent and not based on logical reasoning. From a high-level, abstract perspective, they possess sufficient intelligence and ample **"common sense"** (in fact, they have more common sense than most or even all humans).

So, can a large model, equipped with sufficient intelligence and common sense, communicate to some extent like humans do, based on shared context (common sense) and human consensus? That is, can large models produce correct associative reasoning and empathy in communication?

## Experimental Method
We are using a simple and easily evaluable task as the carrier of this experiment: **text summarization**.

### Evaluation Method

Let's first discuss the evaluation part. We use the evaluation criteria proposed in the paper [G-Eval research paper](https://arxiv.org/abs/2303.16634), evaluating from **Fluency**, **Coherence**, **Consistency**, and **Relevance**. For easier understanding of the results, we take the average of these four dimensions to obtain a comprehensive evaluation.

**Evaluation Scoring Criteria:**
- **Coherence (1-5):** How logically clear the summary presents the information.
- **Consistency (1-5):** The factual accuracy of the summary compared to the source.
- **Fluency (1-3):** The grammatical and structural quality of the summary.
- **Relevance (1-5):** The extent to which the summary captures important information from the source.

**Average Score Range:** 1 to 4.5

During evaluation, we will provide the original article and the AI-generated summary, along with the rating criteria. Therefore, the AI is evaluating with all the necessary information. The evaluation prompt is located in [file](./src/prompt/eval.ts).

If you find **AI evaluating AI** strange or interesting, you can refer to [OpenAI: The New Stack and Ops for AI](https://www.youtube.com/watch?v=XGJNo8TpuVA).

### Experiment Content

We use four methods to obtain AI's summary results. By comparing these four methods, we aim to explore AI's associative reasoning and empathy capabilities.

#### Basic
In the basic method, we directly use the most straightforward way to generate a summary. To avoid interference from prompt quality on the results, our prompts are very direct.

For the basic method, our [prompt](./src/prompt/prompt.ts) is:
```
Generate a summary of the given content.

The summary should be in 200 words, PURE TEXT, DO NOT USE MARKDOWN.
The summary should be in the same language as the original input.

input: {content}
```

Here, the prompt is very straightforward.

The two additional requirements are to request an output of 200 words of pure text, to avoid AI outputting results of different lengths and formats that could affect the evaluation.

In this experiment, we will input the complete original text, so theoretically, the quality of the output summary is the highest and serves as the baseline for our other experimental results.

#### Split Only
Here, we will perform uniform sampling of the article, with parameters:
```
chunkSize = 200,
chunkOverlap = 40,
sampleSize = 5,
```
Understanding these parameters: we uniformly sample 5 chunks from the original article, each chunk is 200 characters long, and there is a 40-word overlap between chunks to prevent context loss due to chunking.

You might be curious about how these parameters are chosen; you can think of them as magic numbers or set based on experience. Because for different texts and sources, setting these three parameters is very challenging, and we don't want to introduce too many control variables into the experiment.

We will summarize the results after chunking. The [prompt](./src/prompt/prompt.ts) here is:
```
Given an evenly sampled portion of the article, generate a summary of the given content.

The summary should be in 200 words, PURE TEXT, DO NOT USE MARKDOWN.
The summary should be in the same language as the original input.

input: {content}
```

Here, we only tell the AI that this is an evenly sampled portion of the article and ask it to summarize. Theoretically, the AI can only summarize based on the provided information, so this summarization method is generally poorer.

We consider this as a baseline where the AI summarizes based only on partial information, which is the worst-case result.

#### Split
Here, we use the same parameters as in Split Only, and all processes are the same, except we modify the [prompt](./src/prompt/prompt.ts):
```
Given an evenly sampled portion of the article,
Based on your human knowledge and understanding, infer the full article from the sampled data and provide a summary.

The summary should be in 200 words, PURE TEXT, DO NOT USE MARKDOWN.
The summary should be in the same language as the original input.
input: {content}
```

The change here is that we tell the AI that this is an **evenly** sampled result and ask the AI, based on fundamental human knowledge and understanding, to infer the complete article and generate a summary.

This experiment is the core test of our project. We hope that the AI can, based on fundamental human knowledge and understanding, infer the complete article and generate a summary. We hope that the output result here is better than the Split Only result with fragmented input.

We emphasize again that the parameters and inputs for Split and Split Only are exactly the same; the only difference is the prompt.

#### Associate
This is our further "wild idea," and we want to try something more interesting. In this process, the pipeline is as follows:
```mermaid
graph LR;
    Original Data-->Evenly Sampled Text Chunks-->D[Let AI associate the full article based on this]-->Generate Summary;
```

Among them, the prompt for association is [prompt](./src/prompt/prompt.ts):
```
This is an evenly sampled portion of the article. Based on this sample, imagine and infer the full article's content.
Please use your understanding to fill in the missing parts and reconstruct the complete article.

The output should be the full article that you inferred,
input: {content}
```

This makes things interesting. In previous experiments, we could roughly predict the quality of the output, but here it's hard to predict what the output will be.

Interested friends can look at the AI's output of the associated results; it's quite interesting to see how AI understands human stories.

### Experiment Output
**If you are not interested in how to run the experiment, you can skip directly to the Experimental Analysis section.**

#### Environment Setup
The experiment uses OpenAI GPT-4o - 2024-05-13.

I am using Azure OpenAI; an `.env.example` is provided in the root directory for your reference. If you are using OpenAI's service, you can refer to [doc](https://js.langchain.com/docs/integrations/platforms/openai/#chat-model) for setup.

Note that to improve speed, all requests in the experiment are concurrent, so please pay attention to your concurrency limits and token consumption.

Install project dependencies:
```bash
yarn
```

#### Running the Experiment
The command to run the experiment is `yarn start`, which will run all `txt` files in the `input` folder and save the results in the `output` folder with filenames as `filename + time`.

In each experimental result, `result.md` is the experiment result for human reading, and other `json` files are raw data during the experiment, convenient for subsequent analysis.

Running `yarn sum` will summarize all results in the `output` folder and output a `csv` file to `sumTest` for comprehensive analysis.

## Experimental Analysis

### Test Data
Currently, in the main branch, we have 6 English articles and 5 Chinese articles, sources including short stories, news articles, and speeches.

Due to time, resources, and energy constraints, we did not look for more data. If you are interested, you can find data yourself and run the experiment locally.

### Experimental Results

| Test Name                                                                                                 | Basic Avg | Split Only Avg | Split Avg | Associate Avg |
|-----------------------------------------------------------------------------------------------------------|-----------|----------------|-----------|---------------|
| Starbucks TetleyJaguar Land Rover: Remembering Ratan Tata's global ambitions-2024-10-11-02-34-14          | 4.5       | 3.25           | 4         | 3.75          |
| Tesla unveiling its long-awaited robotaxi amid doubts about the technology it runs on-2024-10-11-02-33-16 | 4         | 3              | 3.25      | 3.75          |
| The Emperor's New Clothes-2024-10-11-02-34-00                                                             | 4         | 3.75           | 4         | 4             |
| The Little Match Girl-2024-10-11-02-33-22                                                                 | 4.5       | 3.5            | 4.5       | 4.5           |
| Tribute to Diana-2024-10-11-02-33-17                                                                      | 4.5       | 3.75           | 4         | 3.75          |
| Wildlife numbers fall by 73% in 50 years global stocktake finds-2024-10-11-02-33-16                       | 4.5       | 3              | 3.75      | 3.25          |
| 《孔乙己》-2024-10-11-02-34-33                                                                              | 4.5       | 3.75           | 4.5       | 3.5           |
| 欠债400万，中国“淘金客”在非洲“翻盘”-2024-10-11-02-34-05                                                        | 4         | 3.5            | 3.25      | 3.5           |
| 汪曾祺《受戒》-2024-10-11-02-34-04                                                                          | 3.75      | 2.75           | 3         | 2.5           |
| 诺奖2024｜解读：miRNA与众多疾病相关，药物为何难落地？-2024-10-11-02-34-02                                          | 4.25      | 4              | 3.75      | 4             |
| 诺贝尔文学奖丨韩江：人性问题从小跟随我-2024-10-11-02-34-39                                                     | 4.25      | 4              | 3         | 3.75          |
| **Average**                                                                                               | 4.25      | 3.48           | 3.73      | 3.66          |

### Analysis
Overall, this validates our thoughts. Compared to the baseline average score of 4.25, the average scores obtained using different methods are as follows:

- **Split Only:** Average score 3.48
- **Split:** Average score 3.73
- **Associate:** Average score 3.66

It can be seen that the Split Only method has the lowest average score, which aligns with expectations. This is because the model summarizes based only on partial information, lacking a comprehensive understanding of the full text.

In the Split method, we guide the model to infer the full article content based on human fundamental knowledge and understanding, and the average score improves. This indicates that appropriate prompting can stimulate the model's associative reasoning ability, allowing it to generate higher-quality summaries even when information is incomplete.

The Associate method's average score is slightly lower than Split, possibly because reconstructing the full article led the AI to produce some imaginative deviations from the original text, causing the results to diverge from the original data. However, it still scores higher than the Split Only method, indicating that the model has certain associative and reasoning capabilities.

In `sumTest`, we also calculated the average scores for different detailed dimensions in the Evaluation. Interested friends can perform further analysis; there are many interesting points. For example, in **Consistency**, the Associate method is significantly lower than the other methods, proving that the AI's imagination deviates somewhat from reality.

### Thoughts
As we mentioned at the beginning, this is not a project with practical value but is used to validate some of our thoughts.

- Since AI shares similar common sense with humans, i.e., similar context, can this inspire the way we communicate with AI, the way we design prompts, the way we utilize AI, and the way we develop AI applications, etc.?
- Given that AI can perform associative reasoning and, as the results show, the direction of association is somewhat effective, what inspirations does this offer?
- If the sampled articles, in some scenarios, have the same effect as the complete articles, can we say that human articles are not as "unique, noble, exclusively belonging to intelligent species" as we thought, and their logic and development can be inferred by an AI that possesses all human knowledge?
- Can we utilize AI's vast knowledge training and associative abilities to help humans speculate and fill in missing information in cases of incomplete or missing information, similar to how AlphaFold allows AI to predict missing information in a way that optimally connects existing information?
- Can we, when guiding AI to complete tasks, provide only key node prompts and let AI independently perform associative reasoning for the tedious, common, and formatted work in between to complete the task?
- An AI with vast human knowledge and certain logical capabilities is not inferior to humans in many tasks.
- ...

Therefore, this is a project similar to a thinking exploration experiment. If we have to say there is some practical value:
- Perhaps we've proven that summarizing after uniform sampling has a quality close to summarizing using the complete content, so in scenarios where accuracy requirements are not high, we can save token consumption by multiples.
- We have discovered a new magic prompt: `Based on your human knowledge and understanding`